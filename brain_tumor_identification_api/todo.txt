lime iteration count should be 1000


Medical History:

Diagnosed with Stage II Breast Cancer in 2022.
Underwent chemotherapy (6 cycles) and radiation therapy.
Family history of cancer (mother diagnosed with ovarian cancer at age 50).
History of hypertension and Type 2 diabetes.
Allergic to penicillin.

Patient Description:

52-year-old female, non-smoker, occasional alcohol consumption.
Height: 162 cm, Weight: 68 kg (BMI: 25.9).
Works as a school teacher, moderate physical activity.
No significant past surgeries except lumpectomy in 2022.

Symptoms:

Persistent fatigue and weakness.
Lump in the left breast with occasional pain.
Unexplained weight loss (5 kg in 3 months).
Loss of appetite and nausea.
Slight swelling in the underarm area.


from flask import Flask, request, render_template, jsonify, session
from typing import Tuple, Dict, Any
import ollama
import tensorflow as tf
import numpy as np
from PIL import Image
import cv2
from tf_explain.core.grad_cam import GradCAM
from skimage.segmentation import quickshift
from skimage.segmentation import slic
# from tf_explain.core.smoothgrad import SmoothGrad
# from tf_explain.core.integrated_gradients import IntegratedGradients
# from tf_explain.core.occlusion_sensitivity import OcclusionSensitivity

import saliency.core as saliency
from saliency.core.xrai import XRAI
from lime import lime_image
from skimage.segmentation import mark_boundaries
import matplotlib.pyplot as plt
import base64
from io import BytesIO
import keras

from io import BytesIO

from PIL import Image
import numpy as np
import base64
from io import BytesIO
import secrets

tf.data.experimental.enable_debug_mode()
tf.get_logger().setLevel('ERROR')

# Enable eager execution explicitly
tf.config.run_functions_eagerly(True)

app = Flask(__name__)

try:
    # model = tf.keras.models.load_model('model/propose_224_model.h5')
    model = tf.keras.models.load_model('model/restnet50_inbalance_224-model.h5')
    # model = tf.keras.models.load_model('model/googleLeNet_inbalance_224-model.h5')
    # model = tf.keras.models.load_model('model/nin_inbalance_224-model.h5')
    # model = tf.keras.models.load_model('model/vgg16_inbalance_224-model.h5')
    print("Model loaded successfully.")
except Exception as e:
    raise ValueError(f"Failed to load the model: {str(e)}")

IMG_SIZE = 224
CLASS_NAMES = ['Glioma', 'Meningioma', 'Notumor', 'Pituitary']


def preprocess_image(img):
    img = np.array(img)
    img = cv2.bilateralFilter(img, d=2, sigmaColor=50, sigmaSpace=50)
    img = cv2.applyColorMap(img, cv2.COLORMAP_BONE)
    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)
    array = keras.utils.img_to_array(img)
    array = np.expand_dims(array, axis=0)
    return array


def get_last_convolutional_layer(model):
    for layer in reversed(model.layers):
        if isinstance(layer, tf.keras.layers.Conv2D):
            return layer.name
    raise ValueError("No Conv2D layer found in the model.")

def get_specific_convolutional_layer(model, layer_index):
    conv_layers = [layer for layer in model.layers if isinstance(layer, tf.keras.layers.Conv2D)]
    if layer_index < len(conv_layers):
        return conv_layers[layer_index].name
    else:
        raise ValueError(f"Layer index out of range. Model has {len(conv_layers)} Conv2D layers.")


def predict_tumor(image):
    processed_image = preprocess_image(image)
    predictions = model(processed_image)
    predicted_class = np.argmax(predictions, axis=1)[0]
    probabilities = predictions.numpy()[0]
    return CLASS_NAMES[predicted_class], probabilities


def grad_cam_explanation(image, layer_index=-1):
    processed_image = preprocess_image(image)
    predictions = model(processed_image)
    predicted_class_index = np.argmax(predictions.numpy(), axis=1)[0]

    explainer = GradCAM()
    try:
        if layer_index == -1:
            layer_name = get_last_convolutional_layer(model)
        else:
            layer_name = get_specific_convolutional_layer(model, layer_index)
        grid = explainer.explain(
            validation_data=(processed_image, None),
            model=model,
            class_index=predicted_class_index,
            layer_name=layer_name
        )
    except ValueError as e:
        print(f"An error occurred: {e}")
        return np.zeros((IMG_SIZE, IMG_SIZE))

    heatmap = grid.astype(np.float32)
    if heatmap.max() > heatmap.min():
        heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())
    else:
        heatmap = np.zeros_like(heatmap)

    return heatmap

def grad_cam_plus_plus(model, img_array, layer_name, target_class=None):
    grad_model = tf.keras.models.Model(
        inputs=[model.inputs],
        outputs=[model.get_layer(layer_name).output, model.output]
    )

    with tf.GradientTape() as tape1:
        with tf.GradientTape() as tape2:
            with tf.GradientTape() as tape3:
                conv_outputs, predictions = grad_model(img_array)
                if target_class is None:
                    target_class = np.argmax(predictions[0])
                loss = predictions[:, target_class]

            first_grads = tape3.gradient(loss, conv_outputs)[0]
        second_grads = tape2.gradient(first_grads, conv_outputs)[0]
    third_grads = tape1.gradient(second_grads, conv_outputs)[0]

    conv_outputs = conv_outputs[0]
    global_sum = np.sum(conv_outputs, axis=(0, 1))

    alpha_num = second_grads
    alpha_denom = second_grads * 2 + third_grads * global_sum
    alpha_denom = np.where(alpha_denom != 0, alpha_denom, np.ones_like(alpha_denom))

    alphas = alpha_num / alpha_denom
    weights = np.maximum(first_grads, 0)

    cam = np.sum(weights * alphas, axis=-1)
    cam = np.maximum(cam, 0)  # ReLU
    cam /= np.max(cam) if np.max(cam) != 0 else 1  # Normalize between 0 and 1
    return cam, target_class


def grad_cam_pp_explanation(image):
    processed_image = preprocess_image(image)
    predictions = model(processed_image)
    predicted_class_index = np.argmax(predictions.numpy(), axis=1)[0]

    heatmap, _ = grad_cam_plus_plus(model, processed_image, get_last_convolutional_layer(model),
                                    predicted_class_index)
    return heatmap

@tf.custom_gradient
def guided_relu(x):
    def grad(dy):
        return tf.cast(dy > 0, "float32") * tf.cast(x > 0, "float32") * dy
    return tf.nn.relu(x), grad


def guided_backprop(model, img_array, layer_name):
    gb_model = tf.keras.models.Model(
        inputs=[model.inputs],
        outputs=[model.get_layer(layer_name).output]
    )
    layer_dict = [layer for layer in gb_model.layers if hasattr(
        layer, 'activation')]
    for layer in layer_dict:
        if layer.activation == tf.keras.activations.relu:
            layer.activation = guided_relu

    with tf.GradientTape() as tape:
        inputs = tf.cast(img_array, tf.float32)
        tape.watch(inputs)
        outputs = gb_model(inputs)

    grads = tape.gradient(outputs, inputs)[0]
    return grads.numpy()

def guided_gradcam(model, img_array, target_class, layer_name):
    heatmap, _ = grad_cam_plus_plus(model, img_array, layer_name, target_class)
    gb_grads = guided_backprop(model, img_array, layer_name)

    gb_grads = np.squeeze(gb_grads)
    gb_grads = np.maximum(gb_grads, 0)  # ReLU
    gb_grads /= np.max(gb_grads) if np.max(gb_grads) != 0 else 1  # Normalize
    guided_gradcam = heatmap * gb_grads
    return guided_gradcam

def guided_gradcam_explanation(image):
    processed_image = preprocess_image(image)
    predictions = model(processed_image)
    predicted_class_index = np.argmax(predictions.numpy(), axis=1)[0]
    return guided_gradcam(model, processed_image, predicted_class_index, get_last_convolutional_layer(model))

def lime_explanation(image):
    processed_image = np.array(image.resize((IMG_SIZE, IMG_SIZE), Image.Resampling.BILINEAR)) / 255.0

    def custom_segmentation_slic(image):
        return slic(image, n_segments=100, compactness=10, sigma=1)

    # explainer = lime_image.LimeImageExplainer(feature_selection='auto', segmentation_fn=custom_segmentation_slic)

    def custom_segmentation(image):
        return quickshift(image, kernel_size=4, max_dist=2, ratio=0.5)

    # explainer = lime_image.LimeImageExplainer(feature_selection='auto', segmentation_fn=custom_segmentation)

    explainer = lime_image.LimeImageExplainer(feature_selection='auto')

    def predict_fn(x):
        return model.predict(x.reshape(-1, IMG_SIZE, IMG_SIZE, 3), batch_size=32)

    explanation = explainer.explain_instance(
        processed_image,
        predict_fn,
        top_labels=1,
        hide_color=0,
        num_samples=1000,
        batch_size=32
    )

    temp, mask = explanation.get_image_and_mask(
        explanation.top_labels[0],
        positive_only=True,
        num_features=10,
        hide_rest=False
    )

    return mark_boundaries(temp / 2 + 0.5, mask)


def preprocess_image(image):
    image = image.resize((IMG_SIZE, IMG_SIZE))
    image = np.array(image)
    if len(image.shape) == 2:
        image = np.stack((image,) * 3, axis=-1)
    image = image / 255.0
    image = np.expand_dims(image, axis=0)
    return image


def call_model_function(images, call_model_args=None, expected_keys=None):
    target_class_idx = call_model_args['class_index']
    with tf.GradientTape() as tape:
        inputs = tf.convert_to_tensor(images)
        tape.watch(inputs)
        predictions = model(inputs)
        output_layer = predictions[:, target_class_idx]
    gradients = tape.gradient(output_layer, inputs)
    return {saliency.INPUT_OUTPUT_GRADIENTS: gradients}


def encode_image_to_base64(img):
    try:

        if img.dtype == np.float32 or img.dtype == np.float64:
            img = (img * 255).astype(np.uint8)
        elif img.dtype != np.uint8:
            raise ValueError("Image must be a NumPy array with dtype float or uint8.")

        pil_img = Image.fromarray(img)

        buffer = BytesIO()
        pil_img.save(buffer, format="PNG")
        buffer.seek(0)

        base64_encoded = base64.b64encode(buffer.getvalue()).decode("utf-8")

        return base64_encoded

    except Exception as e:
        raise RuntimeError(f"Error encoding image to base64: {str(e)}")


def compute_xrai(image, prediction_class):
    try:
        processed_image = preprocess_image(image)

        xrai_object = saliency.XRAI()

        input_image = processed_image[0]
        if len(input_image.shape) == 2:
            input_image = np.stack((input_image,) * 3, axis=-1)

        xrai_attributions = xrai_object.GetMask(
            input_image,
            call_model_function,
            {'class_index': prediction_class}
        )

        if len(xrai_attributions.shape) == 2:
            xrai_attributions = np.expand_dims(xrai_attributions, axis=-1)
            xrai_attributions = np.repeat(xrai_attributions, 3, axis=-1)

        if len(xrai_attributions.shape) == 2:
            xrai_attributions_3d = np.expand_dims(xrai_attributions, axis=-1)
            xrai_attributions_3d = np.repeat(xrai_attributions_3d, 3, axis=-1)
        else:
            xrai_attributions_3d = xrai_attributions

        grayscale_viz = saliency.VisualizeImageGrayscale(xrai_attributions_3d)
        overlay_viz = saliency.VisualizeImageDiverging(xrai_attributions_3d)

        return {
            'grayscale_viz': grayscale_viz,
            'overlay_viz': overlay_viz
        }

    except Exception as e:
        raise RuntimeError(f"Error computing XRAI: {str(e)}")


@app.route('/upload', methods=['POST'])
def upload_image():
    if 'file' not in request.files:
        return jsonify({'error': 'No file part'}), 400
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'No selected file'}), 400

    if file and file.filename.lower().endswith(('.png', '.jpg', '.jpeg')):
        image = Image.open(file.stream)
        prediction, probabilities = predict_tumor(image)

        labeled_probabilities = {
            CLASS_NAMES[i]: str(probabilities[i])
            for i in range(len(CLASS_NAMES))
        }
        grad_cam = grad_cam_explanation(image)
        lime_img = lime_explanation(image)
        xrai_result = compute_xrai(image, np.argmax(probabilities))
        grad_cam_pp = grad_cam_pp_explanation(image)
        guided_gradcam_img = guided_gradcam_explanation(image)

        def to_base64(img):
            buffer = BytesIO()
            img = np.nan_to_num(img, nan=0.0)
            img = np.clip(img, 0, 1)
            img_uint8 = (img * 255).astype(np.uint8)
            Image.fromarray(img_uint8).save(buffer, format="PNG")
            return base64.b64encode(buffer.getvalue()).decode("utf-8")

        response_data = {
            'prediction': prediction,
            'probabilities': labeled_probabilities,
            'grad_cam': to_base64(grad_cam),
            'grad_cam_pp': to_base64(grad_cam_pp),
            'guided_gradcam': to_base64(guided_gradcam_img),
            'lime': to_base64(np.array(lime_img)),
            'grayscale_viz': to_base64(xrai_result['grayscale_viz']),
            'overlay_viz': to_base64(xrai_result['overlay_viz'])
        }
        return jsonify(response_data)

    return jsonify({'error': 'Invalid file format'}), 400


app.secret_key = secrets.token_hex(32)


@app.route('/chat', methods=['POST'])
def chat():
    if 'conversation_history' not in session:
        session['conversation_history'] = []

    data = request.get_json()
    medical_history = data.get('medical_history', '')
    pt_description = data.get('pt_description', '')
    symptoms = data.get('symptoms', '')
    prediction = data.get('prediction', '')
    user_message = data.get('message', '').strip()
    base64_image = data.get("file", "")

    if not user_message:
        return jsonify({"status": "error", "message": "No message provided"}), 400

    if not is_medical_related(user_message):
        user_message += " (Note: Please keep questions medically relevant)"

    image_description = None
    if base64
